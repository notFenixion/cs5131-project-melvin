{"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNiH+w4lMX2cLW90N81OzR9","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705},{"sourceId":924245,"sourceType":"datasetVersion","datasetId":464091}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identification of Deepfaked Images (and Videos?)\n## By Li Run & Rongyi","metadata":{"id":"aivnid-yA_wd"}},{"cell_type":"markdown","source":"This project aims to train an AI model to be able to identify deepfaked images from real ones with an accuracy of >=XX%.","metadata":{"id":"ROLraV2PBFe3"}},{"cell_type":"markdown","source":"## Data Collection\n\nWe utilized two datasets of images for training our model:\n1. https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n2. https://www.kaggle.com/datasets/dagnelies/deepfake-faces\n\nThe first dataset contains approximately 70,000 training images, 5400 test images and 20,000 validation images of faces for both Real and Fake images each.\n\nThe second dataset contains approximately 95,600 images of faces. Labelling of the images as real or fake can be found under `metadata.csv`.","metadata":{"id":"D-etTf5cCbxy"}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"1Rd_xm2QAvzV"}},{"cell_type":"markdown","source":"Let us first inspect the contents of `deepfake_faces`.","metadata":{"id":"Nof6xTiWEaR1"}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport random\nfrom sklearn.utils.class_weight import compute_class_weight\nimport os, os.path, shutil\n","metadata":{"id":"pkzydyrlhWaO","execution":{"iopub.status.busy":"2024-03-15T03:18:09.436342Z","iopub.execute_input":"2024-03-15T03:18:09.437064Z","iopub.status.idle":"2024-03-15T03:18:09.442918Z","shell.execute_reply.started":"2024-03-15T03:18:09.437032Z","shell.execute_reply":"2024-03-15T03:18:09.441830Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/deepfake-faces/metadata.csv')\ndf.head()","metadata":{"id":"urOb3W5fhY40","outputId":"5279233e-68b7-42bb-c6b0-70cf452ebdb8","colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.status.busy":"2024-03-15T03:18:09.444754Z","iopub.execute_input":"2024-03-15T03:18:09.445095Z","iopub.status.idle":"2024-03-15T03:18:09.591562Z","shell.execute_reply.started":"2024-03-15T03:18:09.445069Z","shell.execute_reply":"2024-03-15T03:18:09.590541Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        videoname  original_width  original_height label        original\n0  aznyksihgl.mp4             129              129  FAKE  xnojggkrxt.mp4\n1  gkwmalrvcj.mp4             129              129  FAKE  hqqmtxvbjj.mp4\n2  lxnqzocgaq.mp4             223              217  FAKE  xjzkfqddyk.mp4\n3  itsbtrrelv.mp4             186              186  FAKE  kqvepwqxfe.mp4\n4  ddvgrczjno.mp4             155              155  FAKE  pluadmqqta.mp4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>videoname</th>\n      <th>original_width</th>\n      <th>original_height</th>\n      <th>label</th>\n      <th>original</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aznyksihgl.mp4</td>\n      <td>129</td>\n      <td>129</td>\n      <td>FAKE</td>\n      <td>xnojggkrxt.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gkwmalrvcj.mp4</td>\n      <td>129</td>\n      <td>129</td>\n      <td>FAKE</td>\n      <td>hqqmtxvbjj.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lxnqzocgaq.mp4</td>\n      <td>223</td>\n      <td>217</td>\n      <td>FAKE</td>\n      <td>xjzkfqddyk.mp4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>itsbtrrelv.mp4</td>\n      <td>186</td>\n      <td>186</td>\n      <td>FAKE</td>\n      <td>kqvepwqxfe.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ddvgrczjno.mp4</td>\n      <td>155</td>\n      <td>155</td>\n      <td>FAKE</td>\n      <td>pluadmqqta.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[df.videoname == 'aaagqkcdis.mp4']","metadata":{"execution":{"iopub.status.busy":"2024-03-15T03:18:09.592945Z","iopub.execute_input":"2024-03-15T03:18:09.593615Z","iopub.status.idle":"2024-03-15T03:18:09.623629Z","shell.execute_reply.started":"2024-03-15T03:18:09.593577Z","shell.execute_reply":"2024-03-15T03:18:09.622574Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            videoname  original_width  original_height label        original\n18722  aaagqkcdis.mp4              90               89  FAKE  eklsrnkwog.mp4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>videoname</th>\n      <th>original_width</th>\n      <th>original_height</th>\n      <th>label</th>\n      <th>original</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18722</th>\n      <td>aaagqkcdis.mp4</td>\n      <td>90</td>\n      <td>89</td>\n      <td>FAKE</td>\n      <td>eklsrnkwog.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We took the name of the first image `aaaqgkcdis.jpg` and looked it up in`metadata.csv`, confirming that the image names corresponded to entries within the csv file allowing us to label the images ourselves.","metadata":{}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"id":"gH6n-ZA3U-ZF","outputId":"c0e0d2f2-f4fe-4a03-cb7f-288fd559093b","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-03-15T03:18:09.626307Z","iopub.execute_input":"2024-03-15T03:18:09.627172Z","iopub.status.idle":"2024-03-15T03:18:09.646923Z","shell.execute_reply.started":"2024-03-15T03:18:09.627133Z","shell.execute_reply":"2024-03-15T03:18:09.646022Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"label\nFAKE    79341\nREAL    16293\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"From here we can see that the Fake:Real ratio in `deepfake_faces` is about 5:1. We need to handle this class imbalance in our data, which we will do by just taking a sample of 16,000 images from each Fake and Real instead.\n","metadata":{"id":"MaqzHZShW2H1"}},{"cell_type":"code","source":"folder_path = '/kaggle/input/deepfake-faces/faces_224'\nimages = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n\n\nprint(images[0])\n\nif not os.path.exists('/kaggle/input/deepfake-faces/faces_224/Fake'):\n    os.makedirs('/kaggle/input/deepfake-faces/faces_224/Fake')\nif not os.path.exists('/kaggle/input/deepfake-faces/faces_224/Real'):\n    os.makedirs('/kaggle/input/deepfake-faces/faces_224/Real')   \n    \nfor image in images:\n    img_name = image.split('.')[0]\n    if df[df.videoname == (img_name + '.mp4')]['label'] == FAKE:\n        new_path = os.path.join(os.path.join(folder_path, 'Fake'), img_name)\n    else:\n        new_path = os.path.join(os.path.join(folder_path, 'Real'), img_name)\n        \n    old_path = os.path.join(folder_path, img_name)\n    \n    shutil.move(old_path, new_path)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-15T03:18:09.648175Z","iopub.execute_input":"2024-03-15T03:18:09.648507Z","iopub.status.idle":"2024-03-15T03:18:55.962639Z","shell.execute_reply.started":"2024-03-15T03:18:09.648479Z","shell.execute_reply":"2024-03-15T03:18:55.961710Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"zrivvmjwai.jpg\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next, we will organize the data into their appropriate categories before splitting them into training and test/validation data.\n\nThis is achieved by splitting the images from `deepfake_and_real_images` into their training/validation/test sets first since those have already been organised for us, then adding on the images from `deepfake_faces`.","metadata":{"id":"UFcL8HOQJWsO"}},{"cell_type":"code","source":"train = tf.keras.utils.image_dataset_from_directory('/kaggle/input/deepfake-and-real-images/Dataset/Train', labels = 'inferred', image_size=(224,224),)\nval = tf.keras.utils.image_dataset_from_directory('/kaggle/input/deepfake-and-real-images/Dataset/Validation', labels = 'inferred', image_size=(224,224),)\ntest =  tf.keras.utils.image_dataset_from_directory('/kaggle/input/deepfake-and-real-images/Dataset/Test', labels = 'inferred', image_size=(224,224),)\n\nprint(train.class_names)","metadata":{"id":"g2wYPQ-LU61m","execution":{"iopub.status.busy":"2024-03-15T03:18:55.963859Z","iopub.execute_input":"2024-03-15T03:18:55.964164Z","iopub.status.idle":"2024-03-15T03:19:53.676882Z","shell.execute_reply.started":"2024-03-15T03:18:55.964139Z","shell.execute_reply":"2024-03-15T03:19:53.675999Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found 140002 files belonging to 2 classes.\nFound 39428 files belonging to 2 classes.\nFound 10905 files belonging to 2 classes.\n['Fake', 'Real']\n","output_type":"stream"}]},{"cell_type":"code","source":"#TODO:\n#somehow separate contents of deepfake-faces/faces_224 into 2 different subfolders with 'Fake' and 'Real' as names (how the fuck do i move them all into a new folder)\n#take a sample of 16,000 of each\n#convert to image dataset using the same command\n#merge them together using - e.g. combined_dataset = dataset_1.concatenate(dataset_2) --> kinda done alr? cant test yet but eh\n#","metadata":{"execution":{"iopub.status.busy":"2024-03-15T03:19:53.678055Z","iopub.execute_input":"2024-03-15T03:19:53.678394Z","iopub.status.idle":"2024-03-15T03:19:53.682753Z","shell.execute_reply.started":"2024-03-15T03:19:53.678363Z","shell.execute_reply":"2024-03-15T03:19:53.681835Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"deepfake_faces = tf.keras.utils.image_dataset_from_directory('/kaggle/input/deepfake-faces/faces_224', image_size=(224,224),)\n\nprint(deepfake_faces.class_names)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T03:19:53.683858Z","iopub.execute_input":"2024-03-15T03:19:53.684103Z","iopub.status.idle":"2024-03-15T03:20:43.438389Z","shell.execute_reply.started":"2024-03-15T03:19:53.684082Z","shell.execute_reply":"2024-03-15T03:20:43.436449Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 0 files belonging to 0 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deepfake_faces \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/deepfake-faces/faces_224\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(deepfake_faces\u001b[38;5;241m.\u001b[39mclass_names)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/image_dataset_utils.py:308\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, data_format)\u001b[0m\n\u001b[1;32m    304\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    305\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    306\u001b[0m )\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    313\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    314\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[1;32m    315\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m     data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[1;32m    323\u001b[0m )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mValueError\u001b[0m: No images found in directory /kaggle/input/deepfake-faces/faces_224. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"],"ename":"ValueError","evalue":"No images found in directory /kaggle/input/deepfake-faces/faces_224. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')","output_type":"error"}]},{"cell_type":"code","source":"# deepfake_faces = deepfake_faces.shuffle()\n\ntrain_and_test2, val2, = tf.keras.utils.split_dataset(deepfake_faces, left_size=0.8, shuffle=True) #80%, 20% -> train+test, val\ntrain2, test2 = tf.keras.utils.split_dataset(train_and_test2, left_size=0.875, shuffle=True) #70%, 10% -> train, test (87.5%, 12.5%)\n\ntrain_merged = train.concatenate(train2)\nval_merged = val.concatenate(val2)\ntest_merged = test.concatenate(test2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T03:20:43.439075Z","iopub.status.idle":"2024-03-15T03:20:43.439402Z","shell.execute_reply.started":"2024-03-15T03:20:43.439238Z","shell.execute_reply":"2024-03-15T03:20:43.439252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are now done with processing our datasets.","metadata":{}},{"cell_type":"markdown","source":"## Training of Model","metadata":{}},{"cell_type":"markdown","source":"Do we want to do transfer learning or try our own architecture first lol","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}